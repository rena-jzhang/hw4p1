{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oxiZ42B4SwQ-"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tests_hw4 import test_prediction, test_generation\n",
        "from tqdm import tqdm\n",
        "from torchnlp.nn import LockedDropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "x5znxQhLSwRC"
      },
      "outputs": [],
      "source": [
        "# load all that we need\n",
        "\n",
        "dataset = np.load('../dataset/wiki.train.npy', allow_pickle=True)\n",
        "devset = np.load('../dataset/wiki.valid.npy', allow_pickle=True)\n",
        "fixtures_pred = np.load('../fixtures/prediction.npz')  # dev\n",
        "fixtures_gen = np.load('../fixtures/generation.npy')  # dev\n",
        "fixtures_pred_test = np.load('../fixtures/prediction_test.npz')  # test\n",
        "fixtures_gen_test = np.load('../fixtures/generation_test.npy')  # test\n",
        "vocab = np.load('../dataset/vocab.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "OZNrJ8XvSwRF"
      },
      "outputs": [],
      "source": [
        "# data loader\n",
        "import random\n",
        "class LanguageModelDataLoader(DataLoader):\n",
        "    \"\"\"\n",
        "        TODO: Define data loader logic here\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, batch_size, shuffle=True):\n",
        "\n",
        "       self.dataset = dataset\n",
        "       # dataset: 579 dataset[0]: 3803\n",
        "       self.batch_size = batch_size\n",
        "       self.shuffle = shuffle \n",
        "       self.seq_len = 90\n",
        "       self.word_len = sum([len(data) for data in self.dataset])\n",
        "    #    print(self.word_len)\n",
        "       self.num_batch = (((self.word_len-1)//self.seq_len + 1)- 1)//self.batch_size + 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batch\n",
        "        \n",
        "    def __iter__(self):\n",
        "        # concatenate your articles and build into batches\n",
        "        dataset_len = len(self.dataset)\n",
        "        data_ids = list(range(dataset_len))\n",
        "        \n",
        "        # . Randomly shuffle all the articles from the WikiText-2 dataset.\n",
        "        if self.shuffle:\n",
        "            random.shuffle(data_ids)\n",
        "        seq = []\n",
        "        # 2. Concatenate all text in one long string.\n",
        "        for id in data_ids:\n",
        "            seq += list(self.dataset[id])\n",
        "\n",
        "        # 3. Group the sequences into batches.\n",
        "        # Calculate the number of batches based on concatenated size and batch size\n",
        "        num_samples = len(seq) - self.seq_len\n",
        "\n",
        "        sample_id = 0\n",
        "        batchx = []\n",
        "        batchy = []\n",
        "        \n",
        "        for i in range(0, num_samples, self.seq_len):\n",
        "            label = seq[i: i+self.seq_len]\n",
        "            target = seq[i+1: i+self.seq_len+1]\n",
        "            sample_id+=1\n",
        "            batchx.append(torch.LongTensor(label))\n",
        "            batchy.append(torch.LongTensor(target))\n",
        "            if  sample_id%self.batch_size==0 or i==num_samples-1:\n",
        "                yield (torch.stack(batchx), torch.stack(batchy))\n",
        "                batchx = []\n",
        "                batchy = []\n",
        "\n",
        "        print('done')\n",
        "\n",
        "        \n",
        "# ld = LanguageModelDataLoader(dataset, batch_size=2, shuffle=True)\n",
        "# len(ld)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Zt-7YsTYSwRI"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "\n",
        "class LanguageModel(nn.Module):\n",
        "    \"\"\"\n",
        "        TODO: Define your model here\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size):\n",
        "        super(LanguageModel, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = 400\n",
        "        self.hid_dim = 1150\n",
        "\n",
        "        # Embedding layer that maps vocab size dim input to a pre-defined dim vector\n",
        "        self.embedding = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.embedding_dim,)\n",
        "\n",
        "        self.lstm1 = nn.LSTM(input_size = self.embedding_dim, hidden_size = self.hid_dim, num_layers=1, \n",
        "                            batch_first=True, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(input_size = self.hid_dim*2, hidden_size = self.hid_dim, num_layers=1, \n",
        "                            batch_first=True, bidirectional=True)\n",
        "        self.lstm3 = nn.LSTM(input_size = self.hid_dim*2, hidden_size = self.hid_dim, num_layers=1, \n",
        "                            batch_first=True, bidirectional=True)\n",
        "        \n",
        "  \n",
        "        # Linear classifier which maps from LSTM hidden dim back to vocab size dim\n",
        "        # self.clf = nn.Linear(self.embedding_dim, self.vocab_size)\n",
        "        self.clf = nn.Linear(self.hid_dim*2, self.vocab_size)\n",
        "        nn.init.uniform_(self.embedding.weight.data, a=-0.1, b=0.1)\n",
        "\n",
        "        # for name, param in self.lstm.named_parameters():\n",
        "        #     self.initialize_weights(param)\n",
        "            \n",
        "        # Keeping the shapes consistent allows you to use weight tying here between\n",
        "        # embedding layer and the linear classifier\n",
        "        # self.clf.weight = self.embedding.weight\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Feel free to add extra arguments to forward (like an argument to pass in the hiddens)\n",
        "        # the likelihood of the occurrence of a word based on the previous words. \n",
        "        # Therefore, the input of your model is the previous text.\n",
        "        # x = torch.LongTensor(x)\n",
        "        x = torch.tensor(x).to(device)\n",
        "        emb = self.embedding(x)\n",
        "        out, hidden = self.lstm1(emb)\n",
        "        # out = self.dropout1(out)\n",
        "        out, hidden = self.lstm2(out, hidden)\n",
        "        # out = self.dropout2(out)\n",
        "        # print(out.shape,hidden[0].shape)\n",
        "        out, (_, _) = self.lstm3(out, hidden)\n",
        "        # out = self.linear(out)\n",
        "        # out = self.dropout3(out)\n",
        "        logits = self.clf(out)\n",
        "        return logits    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kIvZOIfjSwRK"
      },
      "outputs": [],
      "source": [
        "# model trainer\n",
        "\n",
        "class LanguageModelTrainer:\n",
        "    def __init__(self, model, loader, max_epochs=1, run_id='exp'):\n",
        "        \"\"\"\n",
        "            Use this class to train your model\n",
        "        \"\"\"\n",
        "        # feel free to add any other parameters here\n",
        "        self.model = model\n",
        "        self.loader = loader\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.predictions = []\n",
        "        self.predictions_test = []\n",
        "        self.generated_logits = []\n",
        "        self.generated = []\n",
        "        self.generated_logits_test = []\n",
        "        self.generated_test = []\n",
        "        self.epochs = 0\n",
        "        self.max_epochs = max_epochs\n",
        "        self.run_id = run_id\n",
        "        \n",
        "        # TODO: Define your optimizer and criterion here\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3, weight_decay=0, amsgrad=True)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.scaler = torch.cuda.amp.GradScaler()\n",
        "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, factor=0.8, patience=3, verbose=True, threshold=1e-2)\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        self.model.train() # set to training mode\n",
        "        epoch_loss = 0\n",
        "        num_batches = 0\n",
        "        batch_bar = tqdm(total=len(self.loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "\n",
        "        for batch_num, (inputs, targets) in enumerate(self.loader):\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            epoch_loss += self.train_batch(inputs, targets, )\n",
        "            batch_bar.set_postfix(\n",
        "                            loss=\"{:.04f}\".format(float(epoch_loss / (batch_num + 1))),\n",
        "                            lr=\"{:.04f}\".format(float(self.optimizer.param_groups[0]['lr'])))\n",
        "            batch_bar.update() \n",
        "\n",
        "        epoch_loss = epoch_loss / (batch_num + 1)\n",
        "        self.epochs += 1\n",
        "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
        "                      % (self.epochs + 1, self.max_epochs, epoch_loss))\n",
        "        self.train_losses.append(epoch_loss)\n",
        "        # self.scheduler.step(epoch_loss)   \n",
        "\n",
        "\n",
        "    def train_batch(self, inputs, targets):\n",
        "        \"\"\" \n",
        "            TODO: Define code for training a single batch of inputs\n",
        "        \n",
        "        \"\"\"\n",
        "        self.optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast(): \n",
        "            logits = self.model(inputs)\n",
        "            B, T, C = logits.shape\n",
        "            loss = self.criterion(logits.reshape((-1, C)), targets.flatten())\n",
        "        self.scaler.scale(loss)\n",
        "        self.scaler.step(self.optimizer)\n",
        "        # loss.backward() # This is a replacement for loss.backward()\n",
        "        # self.optimizer.step() # This is a replacement for optimizer.step()\n",
        "        self.scaler.update()\n",
        "        return loss\n",
        "    \n",
        "    def test(self):\n",
        "        # don't change these\n",
        "        self.model.eval() # set to eval mode\n",
        "        predictions = TestLanguageModel.prediction(fixtures_pred['inp'], self.model) # get predictions\n",
        "        self.predictions.append(predictions)\n",
        "        generated_logits = TestLanguageModel.generation(fixtures_gen, 10, self.model) # generated predictions for 10 words\n",
        "        generated_logits_test = TestLanguageModel.generation(fixtures_gen_test, 10, self.model)\n",
        "        nll = test_prediction(predictions, fixtures_pred['out'])\n",
        "        generated = test_generation(fixtures_gen, generated_logits, vocab)\n",
        "        generated_test = test_generation(fixtures_gen_test, generated_logits_test, vocab)\n",
        "        self.val_losses.append(nll)\n",
        "        \n",
        "        self.generated.append(generated)\n",
        "        self.generated_test.append(generated_test)\n",
        "        self.generated_logits.append(generated_logits)\n",
        "        self.generated_logits_test.append(generated_logits_test)\n",
        "        \n",
        "        # generate predictions for test data\n",
        "        predictions_test = TestLanguageModel.prediction(fixtures_pred_test['inp'], self.model) # get predictions\n",
        "        self.predictions_test.append(predictions_test)\n",
        "            \n",
        "        print('[VAL]  Epoch [%d/%d]   Loss: %.4f'\n",
        "                      % (self.epochs + 1, self.max_epochs, nll))\n",
        "        return nll\n",
        "\n",
        "    def save(self):\n",
        "        # don't change these\n",
        "        model_path = os.path.join('experiments', self.run_id, 'model-{}.pkl'.format(self.epochs))\n",
        "        torch.save({'state_dict': self.model.state_dict()},\n",
        "            model_path)\n",
        "        np.save(os.path.join('experiments', self.run_id, 'predictions-{}.npy'.format(self.epochs)), self.predictions[-1])\n",
        "        np.save(os.path.join('experiments', self.run_id, 'predictions-test-{}.npy'.format(self.epochs)), self.predictions_test[-1])\n",
        "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-{}.npy'.format(self.epochs)), self.generated_logits[-1])\n",
        "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-test-{}.npy'.format(self.epochs)), self.generated_logits_test[-1])\n",
        "        with open(os.path.join('experiments', self.run_id, 'generated-{}.txt'.format(self.epochs)), 'w') as fw:\n",
        "            fw.write(self.generated[-1])\n",
        "        with open(os.path.join('experiments', self.run_id, 'generated-{}-test.txt'.format(self.epochs)), 'w') as fw:\n",
        "            fw.write(self.generated_test[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xPI7_kZRSwRN"
      },
      "outputs": [],
      "source": [
        "class TestLanguageModel:\n",
        "    def prediction(inp, model):\n",
        "        \"\"\"\n",
        "            TODO: write prediction code here\n",
        "            \n",
        "            :param inp:\n",
        "            :return: a np.ndarray of logits\n",
        "        \"\"\"\n",
        "        # takes as input a batch of sequences, \n",
        "        # shaped [batch size, sequence length]. \n",
        "        # Return the scores for the next word after the provided sequence for each sequence. \n",
        "        # The returned array should be [batch size, vocabulary size] (float) \n",
        "        # inp = inp.to(device)\n",
        "        B, seq_len = inp.shape\n",
        "        logits = model(inp)[:, -1, :]\n",
        "        return logits.detach().cpu().numpy()\n",
        "    \n",
        "        \n",
        "    def generation(inp, forward, model):\n",
        "        \"\"\"\n",
        "            TODO: write generation code here\n",
        "\n",
        "            Generate a sequence of words given a starting sequence.\n",
        "            :param inp: Initial sequence of words (batch size, length)\n",
        "            :param forward: number of additional words to generate\n",
        "            :return: generated words (batch size, forward)\n",
        "        \"\"\"        \n",
        "\n",
        "        # predict the next word given an input using theprediction method\n",
        "        generated_words =[]\n",
        "        for i in range(forward):\n",
        "            logits = TestLanguageModel.prediction(inp, model)\n",
        "            tokens = logits.argmax(axis=1)\n",
        "            generated_words.append(tokens)\n",
        "            prev = inp[:, 1:]\n",
        "            inp = np.concatenate([prev, tokens.reshape(-1,1)], axis=1)\n",
        "        generated_words = np.stack(generated_words).transpose(1,0)\n",
        "        return generated_words\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "TiUrjbEjSwRQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving models, predictions, and generated words to ./experiments/1651267307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/181 [00:00<?, ?it/s]/tmp/ipykernel_2933/2792366076.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x).to(device)\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "No inf checks were recorded for this optimizer.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/home/ec2-user/hw4p1/hw4/training.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000006vscode-remote?line=17'>18</a>\u001b[0m best_nll \u001b[39m=\u001b[39m \u001b[39m1e30\u001b[39m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000006vscode-remote?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000006vscode-remote?line=19'>20</a>\u001b[0m     trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000006vscode-remote?line=20'>21</a>\u001b[0m     nll \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mtest()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000006vscode-remote?line=21'>22</a>\u001b[0m     \u001b[39mif\u001b[39;00m nll \u001b[39m<\u001b[39m best_nll:\n",
            "\u001b[1;32m/home/ec2-user/hw4p1/hw4/training.ipynb Cell 5'\u001b[0m in \u001b[0;36mLanguageModelTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000004vscode-remote?line=36'>37</a>\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000004vscode-remote?line=37'>38</a>\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000004vscode-remote?line=38'>39</a>\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_batch(inputs, targets, )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000004vscode-remote?line=39'>40</a>\u001b[0m batch_bar\u001b[39m.\u001b[39mset_postfix(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000004vscode-remote?line=40'>41</a>\u001b[0m                 loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{:.04f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mfloat\u001b[39m(epoch_loss \u001b[39m/\u001b[39m (batch_num \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000004vscode-remote?line=41'>42</a>\u001b[0m                 lr\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{:.04f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mparam_groups[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m])))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000004vscode-remote?line=42'>43</a>\u001b[0m batch_bar\u001b[39m.\u001b[39mupdate() \n",
            "\u001b[1;32m/home/ec2-user/hw4p1/hw4/training.ipynb Cell 5'\u001b[0m in \u001b[0;36mLanguageModelTrainer.train_batch\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000004vscode-remote?line=61'>62</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(logits\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, C)), targets\u001b[39m.\u001b[39mflatten())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000004vscode-remote?line=62'>63</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale(loss)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000004vscode-remote?line=63'>64</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscaler\u001b[39m.\u001b[39;49mstep(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000004vscode-remote?line=64'>65</a>\u001b[0m \u001b[39m# loss.backward() # This is a replacement for loss.backward()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000004vscode-remote?line=65'>66</a>\u001b[0m \u001b[39m# self.optimizer.step() # This is a replacement for optimizer.step()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2-54-174-197-41.compute-1.amazonaws.com/home/ec2-user/hw4p1/hw4/training.ipynb#ch0000004vscode-remote?line=66'>67</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mupdate()\n",
            "File \u001b[0;32m~/.conda/envs/777/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:336\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ec2-user/.conda/envs/777/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py?line=332'>333</a>\u001b[0m \u001b[39mif\u001b[39;00m optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mstage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m OptState\u001b[39m.\u001b[39mREADY:\n\u001b[1;32m    <a href='file:///home/ec2-user/.conda/envs/777/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py?line=333'>334</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munscale_(optimizer)\n\u001b[0;32m--> <a href='file:///home/ec2-user/.conda/envs/777/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py?line=335'>336</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mfound_inf_per_device\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/ec2-user/.conda/envs/777/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py?line=337'>338</a>\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_opt_step(optimizer, optimizer_state, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///home/ec2-user/.conda/envs/777/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py?line=339'>340</a>\u001b[0m optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mstage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m OptState\u001b[39m.\u001b[39mSTEPPED\n",
            "\u001b[0;31mAssertionError\u001b[0m: No inf checks were recorded for this optimizer."
          ]
        }
      ],
      "source": [
        "# TODO: define other hyperparameters here\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "run_id = str(int(time.time()))\n",
        "if not os.path.exists('./experiments'):\n",
        "    os.mkdir('./experiments')\n",
        "os.mkdir('./experiments/%s' % run_id)\n",
        "print(\"Saving models, predictions, and generated words to ./experiments/%s\" % run_id)\n",
        "device = 'cuda'\n",
        "model = LanguageModel(len(vocab))\n",
        "# model.load_state_dict(torch.load('/home/ec2-user/hw4p1/hw4/experiments/1651263061/model-7.pkl')['state_dict'])\n",
        "model = model.to(device)\n",
        "loader = LanguageModelDataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "trainer = LanguageModelTrainer(model=model, loader=loader, max_epochs=NUM_EPOCHS, run_id=run_id)\n",
        "\n",
        "best_nll = 1e30 \n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    trainer.train()\n",
        "    nll = trainer.test()\n",
        "    if nll < best_nll:\n",
        "        best_nll = nll\n",
        "        print(\"Saving model, predictions and generated output for epoch \"+str(epoch)+\" with NLL: \"+ str(best_nll))\n",
        "        trainer.save()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2FmDqBCSwRf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABDx0lEQVR4nO3deXhb5Znw/+8tyfsub0nsxHYWQhLI4i2FAC1tCWEpYUmXTN8pDHTjpS0t02mZKQVa6Eyn8DJMf2U6k5atU0po2Qo0hYQ1xEATx3E2JyGOs9lJvMb7bj2/PyQ7jiM7iyUdSb4/16XL0tHR0e3t3DrPcj9ijEEppZQayWZ1AEoppYKTJgillFJeaYJQSinllSYIpZRSXmmCUEop5ZXD6gB8KS0tzeTm5lodhlJKhYzNmzc3GGPSvT0XVgkiNzeX0tJSq8NQSqmQISIHR3tOm5iUUkp5pQlCKaWUV5oglFJKeaUJQimllFeaIJRSSnmlCUIppZRXmiCUUkp5pQlCqRDw3sf17D7WanUYaoLRBKFUkOvuG+D232/mn1/cbnUoaoLRBKFUkPtgXwOdvQNsOdTMvvp2q8NRE4gmCKWC3LqKWmIj7dhtwgubq60OR00gmiCUCmIul+HNXXVcfn4Gl81K48WyGgZcukywCgxNEEoFsfLqZurbelg6N5MVBVM51trNB/sarA5LTRCaIJQKYusqanHYhE/NzuAzczJIjHbwvDYzqQDxa4IQkSdEpE5Ednh57h9FxIhI2iivvVlE9npuN/szTqWC1bqKWhZPd5IUE0F0hJ3rFk7h9R3HaO3uszo0NQH4+wriKWDZyI0iMhVYChzy9iIRcQL3AYuBYuA+EUnxX5hKBZ+q+nYq69q5Yk7m0LYVBVPp6XexZttRCyNTE4VfE4QxZj3Q5OWp/wB+AIzW23YlsM4Y02SMOQ6sw0uiUSqcrauoBeCzc08kiAXZScxIj9NmJhUQAe+DEJHlQI0xZusYu2UBh4c9rvZs83a8r4tIqYiU1tfX+zBSpay1rqKWeVMSyU6JHdomIqwomErpweMcaOiwMDo1EQQ0QYhILPAvwL2+OqYxZpUxptAYU5ie7nVZVaVCTkN7D5sPHeeKYVcPg25YlIVN4IUyvYpQ/hXoK4gZQB6wVUQOANlAmYhMGrFfDTB12ONszzalJoS3d9VhDF4TxKSkaC6Zlc6LZTW4dE6E8qOAJghjzHZjTIYxJtcYk4u76SjfGHNsxK5vAEtFJMXTOb3Us02pCWFtRS1ZyTHMnZzo9fmb8rOoae7io6rGAEemJhJ/D3N9FvgQmC0i1SJy2xj7ForIbwGMMU3AA8Amz+2nnm1Khb2u3gE2VNZzxdxMRMTrPlfOm0RClIPntZlJ+ZHDnwc3xqw8zfO5w+6XAl8d9vgJ4Am/BadUkHp/bz3dfS6vzUuDoiPsXLtgMi9vOcJPl/cTH+XXf2U1QelMaqWCzLqKWhKjHRTnOcfcb0VBNl19A/x1u86JUP6hHzvUxOYagK5m6GyAjgbobPTcbzxxv7cTjGscN3PGzxvj4u72bu6zQ8TDtpOfd0RDTArEJEN0MvkxyfxHQgcD7yZD3wUQnTz03PD9iIiBUZqqlBqLJggVXvq63Sf1zkbPCb9p7JN/13H3ydebyASIS4XIeBDb2DebY5Ttds99Oc0x3M/Xt/extqKOS6ZnEJ+WcOJ5BPo6obvZndA66pHGvVxlmohsa4M3xhjNZI90J4yTEkjymW2LiPbVb0aFIE0QKngZA90tnpP54Al/+Ml/5PYm6B1lQR2xQWyq55YGGeefuB+bCnFpJ54fvO+ICuz3C/zmLxU8bQ6y+QufheiI0+7f2NzFpf/+Jv/0ycncXpx6IoF0HT9xf+S2tqNQv8u9rec0y5gOXrUMTyBJU8E5HVJnuL8mTwP76WNVoUcThAos14D7RN5RB+110FHv+VoH7fUnb+9oANcoRekcMSef1NNmeU72Ts/2ESf+6GSwBXeXmzGGdRW1XDQjlYQzSA4AWckxXDQjnT9sa+UbSwuw2c6yKWmg350kuo57ksnxYUnl+MkJprsFjh+E/etPTsQ2hztJOGecSBrOGZA6HZKmgV1PM6FKf3Nq/Ab63Z/gRzvRD//a2eC9ScceCXEZEJ8OCZNh8nz346EkkOZu7hm8Hxl76jFCXGVdOwcaO/nqpdPP6nU35Wdz1x+3sulAE4unp57dm9od7qQaO3aH+EmMcf8um6qgaR807jtx/+AH0DesBIjNAck5nsThSR6pngSSNFWTR5DT347yrr/X8yl+tBP+sO2dTXitu+iIcZ/w4zLcnzCzCiA+40QiiMvwPE6H6KQJ35G61lOcb6zhrd4su2ASP355By+UVZ99gjgXIpCQ6b7lXHTyc8ZAe607YTTucyeNpiporIIDJSOSRwSk5Iy48vA0XSVNdfffKEtpgphoXC53u33bEWg9euJr65Fh2466mxW8iYx3n9DjM9z/yDkXeT/hx2d4Oncn9kn/bKyrqGVBdhKZiWfXMRwb6eDqCyfzl21Huf+6ecRGWvhvLQIJk9y3nItPfm4weZyUODxfD7zv7oQfZIuAlNxTE4dzBiRla/IIEE0Q4aSv231ybxs84R/1nPxrTtxvO3pqu77YID7T3bSTOgNyl7gfD57ohyeAMGzaCQZ1rd2UH27m+0vPO6fXryjI5k+bq3l9xzFuzM/2cXQ+Mjx55C45+TljoO3YiMSxz33lUfUe9Hed2Nce6W62SsqGpCxIzILEKZ6vnvt6ReoTmiBCgTHuDsOhk76Xr61HoMtLNZKIWPeJP3GK+9P+4P3hX+MztS3YYm/uqgPgirkj61aemaJcJ1OdMbxQVh28CWIsIpA42X3LveTk54xx/50P7+toqnL/zVfudieWkU2cEXGe5DHFewJJnOIekaVJZEx6VrCSMe4RJENt/LUnN/sMTwL93ae+Ps7ToZuUDdlFJ/7wh5/89ZNUSFhbcYxpzljOy4w/p9fbbMJN+dn851t7qWnuIis5xscRWkjkxN923qWnPj/Q504SrUfcV8utNSfut9TAvneg/dipgyMiYk8cN3HklcgU9//VBE8imiD8oafdfbLvqHd/ba8b1rFbd/Jjbyd+e5T7k1TCFMjKP/VTf+IUiJ8EjsjAf2/K59p7+vmgspGvXJQzanG+M3FTfjaPvrmXl8qq+danZ/kwwiBnj4Dkqe7baAb6PR/AhiWQlmH397/v/iBmBk5+nSPa+9VHYpb7CiVhinsEWJj2iWiCOFO9nac/6Q/eH97ZNkTcQzYH2/NTZ3ja+DNP7tgd/IObwJ9aJpr1H9fTOzB2cb4zMdUZy+I8Jy+U1XDH5TPHlWzCjt3hPqEneV2Y0m2g3/0/3HoEWqqHXZF4vh4scd8fmUTE5v7/HTlYY6j/btj9EEsmmiCMgZrNJ076oyWA0Wboxqae+CPILjq5c3foDyTTvZ+28ysv1lXUkhIbQUFOyriPtaIgm396fhtlh45TkHMWcxuU+/9z8Aohu9D7Pq4B9/lgePIYOQS8/mP3toHeU18fYslEz1gAT11zclNPTMqJE/2URcNO+pkn/wLj0rTEgBqXvgEXb++u47NzMnHYxz/T+6oLJ3Pvn3fy/OZqTRD+YLOf6EynYPT9BsvEDCaNodaHEa0ODXvdXwd6Tj3GaZOJ55zkx2SiCUIE/u45d2dunKepR9v2VYBsOtBES1ffuJuXBsVHObjqwkm8tvUo931uHtERodOcEVZEPLWrkt1lYMYyNFhleKuFpyVj+ITUsZJJbCr8oMrn34bfEoSIPAFcC9QZYy7wbHsAWA64gDrgFmPMES+vHQC2ex4eMsZc5684AZj+Kb8eXqnRrKuoJcph47Lz0nx2zBX52bxYVsMbO4+xfOEYbe4qOIi4P6BGJ51FMhk28rG9Hlz9fgnNn1cQTwG/An43bNtDxpgfA4jId4B7gW96eW2XMWahH2NTynKDxfkumZnm09nPn5ieSlZyDC+U1WiCCDcnJZOZfn87v5W3NMasB5pGbBteWzgOrwV8lJoYdh1to/p4l8+alwbZbMKN+Vls2FvPsRYvw6iVOkMBr38sIj8TkcPAl3FfQXgTLSKlIvKRiFwfuOiUCpx1FbWIwGfm+DZBgHtOhMvAS1tqfH5sNXEEPEEYY35kjJkKPAN8a5TdcowxhcDfAY+KyIzRjiciX/ckk9L6+no/RKyUf6zbdYz8aSmkJ/h+YaLctDgKc1J4fvNhjNELdXVurFxB5RngJm9PGGNqPF+rgHeBRaMdxBizyhhTaIwpTE9P90ecSvnckeYudtS0+rx5abgVBdnsq+9ga3WL395jIjvc1Mlj71TicoVvAg5oghCR4V30y4HdXvZJEZEoz/00YAlQEZgIlQqMN3ed29oPZ+Pq+ZOJcth4fvNhv73HRGWM4R//tJWH3thDxdHTLNsawvyWIETkWeBDYLaIVIvIbcDPRWSHiGwDlgJ3evYtFJHfel46BygVka3AO8DPjTGaIFRYWVdRy/T0OGakn1txvjORGB3Bsgsm8erWo3T3DZz+BeqMvbSlho373WNwBr+GI78NczXGrPSy+fFR9i0Fvuq5/wFwob/iUspqrd19fFTVyK2X5Pn9vW7Kz+bP5Ud4a1cd18yf7Pf3mwhaOvv42V92kT8tmdrWHjYdaArI79IKwb2Ku1Jh6N099fQNGJb6sXlp0JKZaUxKjNZmJh96aO1ujnf28uD1F7I4z8mmA01hOxBAE4RSAbZ25zHS4iNZOHX8xflOx24TbsjPYv3eBupadU7EeG093MwzfzvELRfnMXdKIkV5Thrae6lq6Dj9i0OQJgilAqi338V7e+r5zPmZ2G2BKcd9U342Ay7Dy+U6J2I8BlyGe17eQXp8FN+7wj3epijXXRBxU5j2Q2iCUCqAPqpqpK2n36+jl0aamRHPwqnJvLC5JmybQgLhD387yPaaFn587VwSot1VnGekx5EaF8nGA5oglFLjtK6ilpgIO5fM8l1xvjOxoiCbPbVt7KgJ3yGZ/lTf1sMv3tjDJTPTuHZYZ7+IUJTrDNuRTJoglAoQYwxv7qrlsvPSAl6G+3PzpxDpsPFCWXVA3zdc/NuaXfT0ufjp8nmnrNRXlOek+ngXR1u6LIrOfzRBKBUgO2paOdrSzRVzJwX8vZNiI7hibiZ/Lq+ht98V8PcPZR9VNfLilhq+8cnpTPcyb2VxnrsfIhyvIjRBKBUg6yqOYRP49PkZlrz/ioJsjnf28fbuOkvePxT19rv48cs7mOqM4Y7LvZfXnjM5kfgohyYIpdS5W1tRS2GuE2ecNSsWXjozjfSEKJ7frM1MZ+qJkv3srWvn/jFW57PbhIKcFDaFYUe1JgjcbcNaikD50+GmTnYfawvI5LjROOw2blyUxbt76mho97JspTpJTXMX//nmXpbOzTxtSfbiPCcf17ZzvKM3QNEFxoRPED39AxT97E3++719VoeiwtjaCv8X5zsTNxVk0+8y/Ln8lJV+1Qg/fXUnAPd+bu5p9x2aDxFmVxETPkFEOeykxUex+eBxq0NRYWxdxTHOy4wnJzXO0jjOy0xgfnYSL2gz05je3l3LGztr+c5nZpGdEnva/ednJxHpsGmCCEeFuSlsOdTMQBjXdVfWae7sZdOB45ZfPQy6KT+biqOtVBzRORHedPUOcO+fdzIrI57bzrAIX3SEnYXZyWHXUa0JAijMcdLe08/uY/oPo3zv7d11DLgMSy0Y3urNdQumEGEXnRMxiv96t5Lq4108cP0FRDrO/BRZlJfCjiOtdPT0+zG6wNIEARTkuIumaTOT8od1FbVkJkZxYVaS1aEAkBIXyWfOz+TlLTX0DeiciOH21bfzP+9VceOiLD4xPfWsXlucl8qAy7DlULN/grOAJgggOyWGzETth1C+1903wHsf1/PZOZnYAlSc70ysKMimsaOX9/boOu6DjDHc9+edREXY+Oer55z16/OnJWMT2Li/0Q/RWUMTBO56KoU5TkoPaIJQvvXhvkY6eweCpv9h0Cdnp5MaF6lzIoZ5bdtRNlQ28IMrZ5OeEHXWr0+IjmDulMSwKtzn1wQhIk+ISJ2I7Bi27QER2SYi5SKyVkSmjPLam0Vkr+d2sz/jBMjPSaGmuYtjLVozX/nO2opa4qMcXDTj7Jor/C3CbuP6RVm8tbs27Mbun4u27j4eeK2CC7OS+LvFOed8nOLcVLYcag6bcib+voJ4Clg2YttDxpj5xpiFwGvAvSNfJCJO4D5gMVAM3Ccifl1dpdDTD1F6MHyyv7KWy+UuzvfJ89KJcgS2ON+ZuCk/m74BwytbdU7Ef6zbS317Dw9ef8G41ukozkuhp9/F9ppm3wVnIb8mCGPMeqBpxLbhQ4XiAG9jS68E1hljmowxx4F1nJpofGrulERiIuzazKR8pry6mfq2nqBrXho0d0oicycnTvhmpp1HWnjqg/18efE0FkxNHtexCnMHC/eFx3nEkj4IEfmZiBwGvoyXKwggCxi+iG61Z5u3Y31dREpFpLS+/tw73CLsNhZMTdKOauUz6ypqsduEy2dbU5zvTNxUkM32mhb2HGuzOhRLuFyGH7+8g5TYSP5p6fnjPl5afBQz0uPCZsKcJQnCGPMjY8xU4BngW+M81ipjTKExpjA9PX1ccRXmOKk42kpnb/iMY1bWWVdRy+I8J0mxEVaHMqrlC6fgsE3cORF/2nyYskPN/MvVc3z2eyrOc7LpQFNYTLy1ehTTM8BNXrbXAFOHPc72bPOrgtwUBlyG8sPN/n4rFeb2N3RQWdduaXG+M5EWH8WnZmfw0pYa+ifYnIimjl7+7a+7Kc51cmO+1waKc1Kc56Stuz8srsoCniBEZNawh8uB3V52ewNYKiIpns7ppZ5tfpU/zTNhTvsh1DitqzgGwGeDPEGAe05EfVsP7+9tsDqUgPr3v+6mvbufB2+44JRV4sYjnAr3+XuY67PAh8BsEakWkduAn4vIDhHZhvvEf6dn30IR+S2AMaYJeADY5Ln91LPNr5JiIjgvM55S7YdQ47Suopa5kxPPqNCb1T59fgYpsRE8P4GamTYfbOK50sPcdmke52Um+PTY2SmxTEmKDou6TA5/HtwYs9LL5sdH2bcU+Oqwx08AT/gptFEV5Dh5bdsRXC4TVDNfVehobO9h88HjfPvTs06/cxCIdNhYvjCLP/ztEC2dfUHdZ+IL/QMufvTSDqYkRfMdP/2OivOclOxrxBjj06uTQLO6DyLoFOak0Nbdz8d1od9+qKzx1u46XMb6tR/Oxk352fQOuHh1W/jPiXj6w4PsPtbGvZ+bR1yUfz4jF+U5qW/r4UBjp1+OHyiaIEYozPVMmNN+CHWO1u6sJSs5hnlTEq0O5YxdkJXI7MyEsJ8Tcaylm0fW7uHy2elcOc9/Cbx4sB8ixJuZNEGMMM0ZS1p8FGXaD6HOQVfvABsq6/nsnIyQaloQEVYUZFN+uJnKunarw/GbB/9SQb/L8JPrfNsxPdLMjHiccZEhX5fJr30QochduC9lwnZUG2PYV99Bd98ALmNwGXAZgxm873J/NcOecz+P9/3N8P0NLhdnvP80ZyxL5wXHGgpn6v299XT3ubgiSNZ+OBvLF03h56/v5oWyan64bPyTxoLN+3vreW3bUe664jympfp38MDgeSTUO6o1QXhRkJPC6zuPUdfWTUZCtNXhBNSbu+r42u9KrQ5jyAPXX8Dff+Lci6cF2rqKWhKiHSye7rQ6lLOWkRDNJ89L56WyGr6/dPa4ahIFm55+9ypxeWlxfP2y6QF5z+I8J2sraqlt7SYzMTTPI5ogvCjIPTEf4qoLJ1scTWC9vbuO+CgHj3xhAXabYBNBBGwinpv705FNwGYb/tizbaz9ZdjxbCfvbx/aXxBPw+f3Vpdz3593kJ0SE9TlKgYNuAxv767j0+dnEGEPzdbbm/KzeXt3GSWVDVx23vgqEwSTVe9Vsb+hg9/dWkx0RGAKJxbnDdZlauJzC7wWrQ56miC8uGBKElEOG6UHJ16CKKls4BPTU4OiaeeXKxfxhf/5kG89U8afvnkxc4O807fs0HEaO3pDavTSSJ+Zk0FSTAQvlFWHTYI41NjJr96p5Jr5kwP6Pc2dnEhcpD2kE0Rofszxs0iHjQXZyROuH+JQYyeHmjq5ZGZwrF0QF+Xg8ZuLSIiO4LanN1HbGtxrdayrqCXCLnwyhE+s0RF2PrdgMq/vOEZrd5/V4YybMYb7XtmBwyb8+Jq5AX1vh91Gfk5KSM+o1gQxioLcFHbWtNDdN2B1KAFTss9dauGSWWkWR3LCpKRonriliNauPm59alPQLghvjGHtzmNcNCONhOjQnmi2omAqPf0u1mw7anUo47a2opZ39tTzvSvOY1JS4PsBinOd7Klto7kzNBdl0gQxisKcFPpdhq0TqHDfhsoGMhOjmJEeb3UoJ5k7JZFf/V0+u462cufqLUFZJbOyrp0DjZ0h3bw0aEF2EjPS40J+TkRHTz8/eWUn509K4JaLcy2JoSjPiTGhO69KE8QoBgv3TZRmJpfL8EFlA0tmpgXl+P3Lz8/gJ9fN481ddTz4lwqrwznF2opaAK6YE/oJwj0nYiqlB4+zv6HD6nDO2S/f3suRlm5+dsMFOCwaNLBwajIRdgnZZiZNEKNIiYtkRnrchFlAqOJoK8c7+7hkZvA0L4309xflcuuSPJ4sOcBTJfutDuck6ypqmZ+dZEkzhj/csCgLm8CLIVrA7+PaNh5/fz9fLJxKQY51Q46jI+wsyE4O2QlzmiDGUJjjZPPB47iCsEnD10oq3f0PS4I4QQD86Jo5fHZOJj99rYK3dtVaHQ4Ada3dlB9uDourh0GTkqK5ZFY6L5bVhNzfvzGGe17eQXy0gx9eZf2Ev6I8J9urW0JyITJNEGMoyE2hpauPffXhW3pg0IbKBmZlxAf9hB67TfjlyoXMnZLIt5/dwo6aFqtD4s1ddQBc4cfaPla4KT+LmuYuPqpqtDqUs/LSlho27m/i7mXn44yLtDocivOc9LsM5YearQ7lrGmCGENhjmfCXJg3M3X3DbDpQFPQXz0Mio10D39NjnEPfz3a0mVpPOsqjjHNGctsH68rYLUr500iIcoRUp3VLZ19/OuaXSyalswXCqee/gUBUJCTggj8LQTLbmiCGENeWhzOuMiw76guO3Sc7j5XUPc/jJSZGM3jtxTR0TPAbU+V0m7R8NeOnn5K9jVyxdzMoOzcH4/oCDvXLpjMX3ccs+zne7YeXruHpo5eHrz+gqBZzyUxOoI5kxJDsqPabwlCRJ4QkToR2TFs20MisltEtonISyKSPMprD4jIdhEpFxHLCgOJCPnTUsL+CqKksgG7TUKuftCcyYk89uV89tS28e0/lFmypvL6j+vp7XeFxfBWb1YUZNPVN8Ca7cE/J2JbdTO//9tBbr44l3lTkqwO5yTFeU7KDh2ntz+01v325xXEU8CyEdvWARcYY+YDHwP/PMbrLzfGLDTGFPopvjNSmJvC/oYOGtp7rAzDrzZUNrJwanJITvD65Hnp/HT5PN7ZU89PX6vAmMB2qK6rqCU5NmKoOTLc5E9LIS8tjheCvJlpwOXumE6Pj+KuK86zOpxTFOc56e5zseOI9X1mZ8NvCcIYsx5oGrFtrTFm8Fr1IyDbX+/vK+HeD9HS2cf26uaQ6X/w5suLc/j6ZdP53YcHebLkQMDet2/AxVue4nxWjbP3NxHhpvws/ra/icNNwbs62h82HmJbdQv3XDs3KD/oFIXoAkJW/lXfCvx1lOcMsFZENovI18c6iIh8XURKRaS0vr7e50FekJVEpN0Wtgniw6pGXIaQ6n/w5u5l53PlvEwe+EsFa3ceC8h7bjrQREtXH0vDtHlp0A352YjAC0E6J6K+rYdfvL6bJTNT+dz84CyumZ4QxfS0uJDrh7AkQYjIj4B+4JlRdrnEGJMPXAXcISKXjXYsY8wqY0yhMaYwPd33RdKiI+xcmJ1EaYj9Ys9USWUDsZF2Fk5NtjqUcbHZhEe/uIj5WUncubqc7dX+v5RfV1FLpMPGpbNCtzjfmchKjuHiGam8UFYdlHMi/u2vu+juG+Cny/27Stx4FeU62XQgtOZVBTxBiMgtwLXAl80oDcbGmBrP1zrgJaA4YAF6UZiTwo6a1rAs3FdS2cDiPCeRjtBvIomJtPObmwtxxkVy29ObONLsv+GvxhjWVdRyycw0vy18H0xuys/mcFNX0H0C/qiqkRfLavjGZTOCrobYSEV5Tlq6+vi4rs3qUM5YQM8KIrIM+AFwnTHGa4OmiMSJSMLgfWApsMPbvoGSn5NC74ArKCZl+VJNcxdVDR0h3f8wUkaCu/prV+8Atz61iTY/lazefayN6uNdYTt6aaRlF0wiLtIeVHMievtd/Phl94JSd1w+0+pwTmtxXuj1Q/hzmOuzwIfAbBGpFpHbgF8BCcA6zxDW//bsO0VE1nhemglsEJGtwEbgL8aY1/0V55koyAnPwn2D5TWCqby3L8yelMB//Z989ta1860/bPHL8Nd1FbWIuBfYmQhiIx1cM38ya7YfDZqSEU+U7GdvXTs/uW4eMZGBWSVuPLJTYpiUGB1SE+b8dm1sjFnpZfPjo+x7BLjac78KWOCvuM5FWnwUeWlx7pK9n7Q6Gt8pqWwgLT4y7GYAA1w6K50Hr7+Af35xO/e9spMHr/dt+/S6iloWTU2eUGuW35SfzR9Lq7ny0fU446KIj7ITF+kgPspBXJSD+GjP/Ui7+/HI7VEO4iMdxEXZxz3qq6a5i/98cy9L52bymRCpgSUiFOU52bi/EWNMUPeXDAr/xlMfKchJ4e3ddSHziz0dYwwlQVze2xdWFk/jYGMn//3ePvLS4vjqpb5ZrP5Icxfba1r44TLrC8EFUnGekzsun8H+hg7aewbo6Omnsb2Ttu5+Onr76ejpp2/gzDpgoxw2EqLdSeNEknEnloRo97ZTk4x9aPujb+4F4N7PBXaVuPEqznPy6tYjHGrqJCc1zupwTuucE4SIfNcY86gPYwlqhTkpPL+5mqqGjqDvDDsTe2rbaGjvDav+B29+cOVsDjV18LM1u8hOiWXZBeNfa/tNTxXZidL/MEhE+Kcrx06KPf0DdHiSx2DiaO9xJ4+Onn7aewZo97q9n4b2Xg40dg5t7+wde1DID5edT3ZKrC+/Rb8r9syH2Li/KbwTBHAX8KiP4gh6hbknJsyFQ4LYsDc0ynuPl80mPPKFhRxp/ojvPreF55IuYsE4h/Suq6hlelocMzNC/+/A16IcdqIcdp9UUR1wGTp7++noGaC9p2/oqqW9p59Ih41PhuDw4lkZ8STHRrDpQBOfD5JigmMZT0NgeLZLjGJ6WjxJMRFsDtGlA0f6YF8j09PiyEqOsToUv4uOsPObrxSSFh/FbU+XUn383GcEt3b38VFV44S7erCC3SYkREcwKSmamRkJLJyazJKZaVw5bxKXz84ImmJ8Z8NmEwpznGwMkY7q8SSI0Jnt4QM2m1CQk0LpwdD4xY6lb8DFR1WNYX/1MFx6QhRP3lJET797+GvrOQ5/fXdPPX0DRhOEOmfFeSkcaOykrq3b6lBOa8wEISJtItLq5dYGZAUoxqBRkJPCvvoOjnf0Wh3KuJQfbqazd2BCJQiAWZkJ/Pf/KaCqvoM7nimj7xyGv66rqCU1LpJF08KzOJ/yv+K8VAA27Q/+1ogxE4QxJsEYk+jllmCMCf6Bxz4WLoX7NuxtwCZw0fRUq0MJuCUz0/jXGy7k/b0N3PvnHWdV/bW338W7u+v4zJwM7CHYvKGCw7wpicRE2Nm4P/hX6jvnJiYROeTLQELBgqnJRNgl5CfMlVQ2cGF2MkmxwVf1MhC+UDSVOy6fwbMbD7NqfdUZv+5v+xtp6+ln6dzxj4RSE1eE3UZ+TjIbQ6A/Uzupz0J0hJ15U5IoC+EE0dbdx5bDzVwyc+JdPQz3j1fM5tr5k/m3v+4+48Vw1lXUEhNhD7uZ5yrwinNT2X2slZYu/5SC8RXtpD5LBTkpbK1uDrmVoQZt3N/EgMtMuP6HkWw24eHPLyB/WjLfe66cLYfGTvqDxfkunZVGdMSEa11VPlaUl4IxsDnIB72crpP6rlFu/whMyEHghTkp9PSH3spQgzZUNhAdYSNfO1mHhr9mJkbztd+Vjrkgzo6aVo62dOvoJeUTi6amEGEXNgZ5R/XpriASRrnFA//p39CCU8HghLkQaD/0pqSygaJcp34K9kiNj+KJW4ro7XfxD09tGvWSf13FMWxCyNT9UcEtJtLOhVlJQVc+faQxZ1IbY34SqEBCRUZCNNOcsZQebOJr+Ka2T6DUtXbzcW07N+UH/UqvATUzI57/+ftCvvLE3/i/z2zmqX8oJmJEMbm1FbUU5jh9MkNYKXCvD/HEhv109w0E7Qe20zUx3TvG7ceBCjLYFOaksPng8bMaIhkMSvZNjPIa5+KiGan8243zKals5J6XTh7+eripk93H2rR5SflUca6TvgHDlkPNVocyqtM1MXV4uQHcBvzQj3EFtYLcFBraeznYGLyLuHuzYW8jKbERzJ2caHUoQWlFQTbf+fRMnis9zK/f2ze0fV3FxCzOp/yrMMeJCEFdduN0TUz/b/C+Z5W3O4F/AFYD/2+014W7gmET5nLTgr8iI5wo733xzLSQrGETKN+74jwONnXyi9f3MM0Zy7Xzp7CuopbzMuND5netQkNSbASzMxOCuh/itMNcRcQpIg8C23AnlHxjzA8960WP9bonRKRORHYM2/aQiOwWkW0i8pKIJI/y2mUiskdEKkXk7rP7lvzvvIwEEqIdITVhbl99B8dau7lEm5fGJCL8+03zKcpN4a4/buWd3XVsPNCkVw/KL4rznJQdOn5OZV8C4XR9EA8Bm4A24EJjzP3GmDM9Kz4FLBuxbR1wgTFmPvAx8M9e3tMOPAZcBcwFVopIUK0KYrMJ+dNSgn4M83BDy4tqgjit6Ag7//P3hUxOiua2pzcx4DJcobOnlR8U5znp7B1g55FWq0Px6nRXEP8ITAHuAY4ML9YnImN+R8aY9UDTiG1rjTGDC9p+BHgbTlMMVBpjqowxvbibs5afwfcSUIU5KXxc205LZ3DPhBy0obKBac5YpjpDa4EVqzjjInnyliISoiPITIxiflaS1SGpMDS4gNCmIO2HOF2xPpsxJsZL0b4EY8x4ezpvBf7qZXsWcHjY42qCsHLs4HyIstPMwA0G/QMuPto3scp7+8L09Hhe+dYSfnfrYu23UX6RkRhNbmosG4O0H2J8K4efIxH5EdAPPOODY31dREpFpLS+vn78wZ2hhVOTsdskJNaH2FbTQltPvzYvnYOc1DhmT0qwOgwVxopynWw60ITLFXzD5gOeIETkFuBa4MvG+0SCGmD4WnzZnm1eGWNWGWMKjTGF6emBW4IwNtLB3MmJIVH6u2RvAyLusf5KqeBSlOekubOPyvp2q0M5RUAThIgsA34AXGeMGW0SwSZglojkiUgk8CXglUDFeDYKclIoP9wctCMQBm2obGDelESdBaxUEFqc5+6HCMb5EH5LECLyLPAhMFtEqkXkNuBXuGs5rRORchH5b8++U0RkDYCnE/tbwBvALuCPxpid/opzPApzU+juc1ERpCMQADp7+yk7dJwlM7R5SalgNM0ZS0ZCVFAmiDEnyo2HMWall82Pj7LvEeDqYY/XAGv8FJrPFOa4M3/pweMsmJpsbTCj2Li/ib4BLe+tVLASEYry3P0QxhhEgmdAhCWd1OFiUlI0WckxQT0foqSygUi7jSLPcDqlVPBZnOfkaEs31ce7rA7lJJogxqkwN4XSA8FbuG9DZSMFOSnERAZntUilFEMf4IKtmUkTxDgV5qRQ19YTdJkfoKG9h11HW3WJTKWC3OzMBBKjHUFXl0kTxDjlDyvcF2w+2NcIaHlvpYKdzSYU5Tr1CiLcnD8pkfgoR1BOmCvZ20BCtIMLtUyEUkGvKM9JVUMH9W09VocyRBPEONltwqJpyZQG2RKkxhg2VDZw8YxU7FomQqmgN9gPURpEzUyaIHygICeFPbVttHYHT+G+g42d1DR3aXkNpULEhVlJREfY+FsQNTNpgvCBwhwnxhBUSwduqNTlRZUKJZEOG4umpgRVR7UmCB9YOC0Zm8DmIPrFllQ2MCUpmjxdBU2pkFGc52TX0dagaY3QBOED8VEOzp+UyOYgKf094DJ84CnvHUyzMpVSYyvOc+IywTMqUhOEjxTmprDlUDP9QVC4b+eRFlq6+nT+g1IhZtG0ZBw2CZoFhDRB+EhBTgqdvQPsPtZmdShD/Q8Xa4E+pUJKbKSDC7KSgqYfQhOEjxQG0RC1ksoGzp+UQHpClNWhKKXOUnGek62HW+juG7A6FE0QvpKVHMPkpGhKLW477O4bYNOB4zp6SakQVZTrpHfAxdbDzVaHognClwpyUizvXCo9cJzefpfOf1AqRBV51rsPhmYmTRA+VJCTwtGWbo40W1e4b0NlAw6bUJyn5b2VCkXJsZHMzkwIiglzmiB8aPgCQlYpqWwgf1oKcVF+WwtKKeVnRXkplB08bvmoSH8uOfqEiNSJyI5h2z4vIjtFxCUihWO89oCIbPcsS1rqrxh9bc7kBGIj7ZZNmDve0cuOIy3a/6BUiCvOS6Wjd4CKo9YuZ+zPK4ingGUjtu0AbgTWn8HrLzfGLDTGjJpIgo3DbmPh1GTLriA+rGrEGLhkVqol76+U8o3iIFlAyG8JwhizHmgasW2XMWaPv94zGBTmpLDraCvtPf0Bf+8NlQ3ERzmYn50c8PdWSvnOpKRopjpjLO+oDtY+CAOsFZHNIvL1sXYUka+LSKmIlNbX1wcovNEV5LqnypdbULivpLKBT0x3EmEP1l+rUupMFeemssni5YyD9UxyiTEmH7gKuENELhttR2PMKmNMoTGmMD09PXARjmLRtGREAl9L5XBTJwcbO7X/QakwUZyXQlNHL/vq2y2LISgThDGmxvO1DngJKLY2ojOXGB3B7MyEgK8wV+Ipr6HzH5QKD0VD/RDWjYoMugQhInEikjB4H1iKu3M7ZBTkuAv3DbgCd2m4obKBjIQoZmbEB+w9lVL+k5cWR1p8FBv3N1oWgz+HuT4LfAjMFpFqEblNRG4QkWrgIuAvIvKGZ98pIrLG89JMYIOIbAU2An8xxrzurzj9oTA3hfaefvYEqHCfy2X4cF8jl2h5b6XChohQnJfCJguXM/bbbCpjzMpRnnrJy75HgKs996uABf6KKxAGJ8xtPtjE3CmJfn+/3cfaaOzo1f4HpcJMca6TNduPUX28k+yU2IC/f9A1MYWD7JQYMhKiAjYfokSXF1UqLBV5SuZYNdxVE4QfiAgFOSmUBujScENlAzMz4pmUFB2Q91NKBcb5kxJJiHJY1lGtCcJPCnJSqGnu4lhLt1/fp6d/gI37m3T0klJhyG4TCnNT9Aoi3AwuIOTv+RBbDjXT1TegzUtKhamiPCeVde00tvcE/L01QfjJvCmJREfY/D4foqSyAbtNWDxdy3srFY4G6zJZMZpJE4SfRNhtLMhO9vsVxIbKBhZkJ5EYHeHX91FKWePC7CSiHDZLCvdpgvCjwtwUdh5ppbPXP4X7Wrv72Hq4WfsflApjUQ47C6cmW9IPoQnCjwpyUhhwGcr9tLbsR/sacRkd3qpUuCvOc7LzSEvAq0RrgvCj/GnutWXL/NTMVFLZQEyEnUWe91FKhafiPHeV6EAXAdUE4UfJsZHMyoj324S5DZUNLJ7uJNKhv0alwln+tBTsNmFTgPsh9MziZ4W57rVlXT4u3He0pYt99R3a/6DUBBAX5WDelEQ2BrgfQhOEnxXkOGnt7mdvnW9rupdUuis8av+DUhNDca6T8sPN9PQPBOw9NUH4WWGOu3/A1/MhSiobSIuPZHZmgk+Pq5QKTkV5Tnr7XWyrbgnYe2qC8LOc1FhS4yLZ7MNJLsYYNlQ2cPGMNGw2Le+t1ERwYgGhwDUzaYLws8HCfZsP+S5B7K1rp76tR/sflJpAnHHuQS+aIMJMYW4KBxs7qW/zTS2VDXs95b1naYJQaiIpynNSdvB4wFar9OeKck+ISJ2I7Bi27fMislNEXCJSOMZrl4nIHhGpFJG7/RVjoBQMW0DIF0oqG8hLiyMrOcYnx1NKhYbFeU7aevrZdbQ1IO/nzyuIp4BlI7btAG4E1o/2IhGxA48BVwFzgZUiMtdPMQbEBVmJRDpsPlkfom/AxUdVjSyZmeqDyJRSoSTQ/RB+SxDGmPVA04htu4wxe07z0mKg0hhTZYzpBVYDy/0UZkBEOewsyE7yyYS5rYeb6egd0P4HpSagKckxZCXHBKwuUzD2QWQBh4c9rvZs80pEvi4ipSJSWl9f7/fgzlV+Tgo7j7TQ3Te+McwbKhsQgYuma4JQaiJanOdk4/4mjPF/P0QwJoizYoxZZYwpNMYUpqenWx3OqApznPQNGLaOs3BfSWUD87OSSIrV8t5KTURFeU4aO3qpaujw+3sFY4KoAaYOe5zt2RbSCjwT5sYz3LW9p58th5p19rRSE9hgP0Qg6jIFY4LYBMwSkTwRiQS+BLxicUzj5oyLZHp63LgmzG3c30i/y2j/g1IT2Iz0OFLjIgPSUe3PYa7PAh8Cs0WkWkRuE5EbRKQauAj4i4i84dl3ioisATDG9APfAt4AdgF/NMbs9FecgVTomTB3roX7NuxtJMphIz9Hy3srNVGJCEW5zoAU7nP468DGmJWjPPWSl32PAFcPe7wGWOOn0CxTmOPkj6XVVDW0MzPj7GsolVQ2UJznJDrC7ofolFKhoijPyes7j3GkuYspfpwPFYxNTGGrINdTuO8cmpnq2rrZU9um/Q9KKRbnefoh/HwVoQkigKanxZESG3FO8yE+8JT31v4HpdScyYnERzn83g+hCSKABgv3ncsSpBsqG0iOjWDu5EQ/RKaUCiV2m5Cfk+L3Kwi/9UEo7wpynLy5q47G9h5S46PO6DXGGEoqG1gSRuW9+/r6qK6upru72+pQlI9FR0eTnZ1NRITO1fGnxXlOHnpjD8c7ekmJi/TLe2iCCLBCTz/E5oPHWTpv0hm9pqqhg6Mt3WHV/1BdXU1CQgK5ubmIhEfSU+4PM42NjVRXV5OXl2d1OGFtaD7EgaYzPpecLW1iCrALs5KItNvYfBbNTCWVnvLeYVSgr7u7m9TUVE0OYUZESE1N1SvDAJifnUSkw+bXZiZNEAEWHWHngqzEs+qo3rC3geyUGKY5Y/0YWeBpcghP+nsNjOgIOwuzk/3aUa0JwgIFOSlsrz6zwn39Ay4+rGrkkplp+o+nlDpJUV4KO4600tHT75fja4KwQEGOk94BFzuPnH7x8e01LbR194dV/0MwaGxsZOHChSxcuJBJkyaRlZU19Li3t3fM15aWlvKd73zntO9x8cUX+yTWd999l2uvvdYnx1LhpTgvlQGXocyHSxoPp53UFhgs3Fd64PjQanOjGex/uHhG+PQ/BIPU1FTKy8sBuP/++4mPj+f73//+0PP9/f04HN7/PQoLCyksHHVBxCEffPCBT2JVajT505Kxibtw36WzfF/NWhOEBdIToshNjaX04HG+cZp9N1Q2MHdy4hkPiQ1FP3l1JxVHfLuE4twpidz3uXln9ZpbbrmF6OhotmzZwpIlS/jSl77EnXfeSXd3NzExMTz55JPMnj2bd999l4cffpjXXnuN+++/n0OHDlFVVcWhQ4f47ne/O3R1ER8fT3t7O++++y73338/aWlp7Nixg4KCAn7/+98jIqxZs4a77rqLuLg4lixZQlVVFa+99tqoMTY1NXHrrbdSVVVFbGwsq1atYv78+bz33nvceeedgLsPYP369bS3t/PFL36R1tZW+vv7+fWvf82ll17K2rVrue++++jp6WHGjBk8+eSTxMfHc/fdd/PKK6/gcDhYunQpDz/88Ln/AlRAJERHMHdKot/qMmmCsEhBjpN399RhjBm1b6Gzt5+yg83csiQ3sMFNYNXV1XzwwQfY7XZaW1t5//33cTgcvPnmm/zLv/wLL7zwwimv2b17N++88w5tbW3Mnj2b22+//ZQ5AFu2bGHnzp1MmTKFJUuWUFJSQmFhId/4xjdYv349eXl5rFw5WvmyE+677z4WLVrEyy+/zNtvv81XvvIVysvLefjhh3nsscdYsmQJ7e3tREdHs2rVKq688kp+9KMfMTAwQGdnJw0NDTz44IO8+eabxMXF8e///u888sgj3HHHHbz00kvs3r0bEaG5udlXP1LlZ8W5qby67QgDLoPdx/OkNEFYpDA3hRfKqtnf0MH09Hiv+2w6cJzeAVfY9z+c7Sd9f/r85z+P3e4uhtjS0sLNN9/M3r17ERH6+vq8vuaaa64hKiqKqKgoMjIyqK2tJTs7+6R9iouLh7YtXLiQAwcOEB8fz/Tp04fmC6xcuZJVq1aNGd+GDRuGktSnP/1pGhsbaW1tZcmSJdx11118+ctf5sYbbyQ7O5uioiJuvfVW+vr6uP7661m4cCHvvfceFRUVLFmyBIDe3l4uuugikpKSiI6O5rbbbuPaa6/VPo8QctfS8/jRNXN8nhxAO6ktM9QPMcZw15LKBiLtNopytbx3oMTFxQ3d//GPf8zll1/Ojh07ePXVV0cd2x8VdaL5z263099/6oiSM9lnPO6++25++9vf0tXVxZIlS9i9ezeXXXYZ69evJysri1tuuYXf/e53GGO44oorKC8vp7y8nIqKCh5//HEcDgcbN25kxYoVvPbaayxbtsyn8Sn/iY9y+CU5gCYIy8xMjycx2jHmAkIb9jaQn5NMbKRe6FmhpaWFrCz3cuhPPfWUz48/e/ZsqqqqOHDgAADPPffcaV9z6aWX8swzzwDu0U1paWkkJiayb98+LrzwQn74wx9SVFTE7t27OXjwIJmZmXzta1/jq1/9KmVlZXziE5+gpKSEyspKADo6Ovj4449pb2+npaWFq6++mv/4j/9g69atPv9+VejRM49FbDZ34b7RliBtbO+h4mgr3196XoAjU4N+8IMfcPPNN/Pggw9yzTXX+Pz4MTEx/Nd//RfLli0jLi6OoqKi077m/vvv59Zbb2X+/PnExsby9NNPA/Doo4/yzjvvYLPZmDdvHldddRWrV6/moYceIiIigvj4eH73u9+Rnp7OU089xcqVK+np6QHgwQcfJCEhgeXLl9Pd3Y0xhkceecTn368KPWLMua1udtoDizwBXAvUGWMu8GxzAs8BucAB4AvGmFPOkCIyAGz3PDxkjLnuTN6zsLDQlJaWjj/4AHnsnUoeemMP5fdeQXLsycW2Xt16hG8/u4WX/u/FLJoWfk1Mu3btYs6cOVaHYbn29nbi4+MxxnDHHXcwa9Ysvve971kd1rjp7zd0iMhmY4zXcdv+bGJ6ChjZkHk38JYxZhbwluexN13GmIWe2xklh1A02A/hrS5TSWUDCdEOLsxKCnRYKoB+85vfsHDhQubNm0dLSwvf+MbpBj4rFTj+XHJ0vYjkjti8HPiU5/7TwLvAD/0VQ7BbkJ2MwyaUHjzOZ+ZkDm03xvD+3gYump6Kw67dROHse9/7XlhcMajwFOizT6Yx5qjn/jEgc5T9okWkVEQ+EpHrAxNa4MVE2pk3JfGUjupDTZ3UNHdxyazwHt6qlApuln08Ne7Oj9E6QHI8bWJ/BzwqIjNGO46IfN2TTErr6+v9EapfFeQ42VrdTG+/a2hbiWd50XCf/6CUCm6BThC1IjIZwPO1zttOxpgaz9cq3M1Qi0Y7oDFmlTGm0BhTmJ7u+1ok/laYm0JP/8mF+0oqG5icFM30tLgxXqmUUv4V6ATxCnCz5/7NwJ9H7iAiKSIS5bmfBiwBKgIWYYAVjuiodrkMJfsaWKLlvZVSFvNbghCRZ4EPgdkiUi0itwE/B64Qkb3AZz2PEZFCEfmt56VzgFIR2Qq8A/zcGBO2CSIjMZqpzhhKPf0QFUdbae7s4xJtXvKryy+/nDfeeOOkbY8++ii33377qK/51Kc+xeAw6quvvtprvaL777//tEXuXn75ZSoqTvxJ33vvvbz55ptnEb13WhZc+Zo/RzGNVnnsM172LQW+6rn/AXChv+IKRoU5Tt7f24Axhg2D5b3DaHnRYLRy5UpWr17NlVdeObRt9erV/OIXvzij169Zs+ac3/vll1/m2muvZe7cuQD89Kc/PedjKeVPOpM6COTnpPDSlhoONXVSUtnA7MwEMhKirQ4rcP56Nxzbfvr9zsakC+Gqn4/69IoVK7jnnnvo7e0lMjKSAwcOcOTIES699FJuv/12Nm3aRFdXFytWrOAnP/nJKa/Pzc2ltLSUtLQ0fvazn/H000+TkZHB1KlTKSgoANxzHFatWkVvby8zZ87kf//3fykvL+eVV17hvffe48EHH+SFF17ggQce4Nprr2XFihW89dZbfP/736e/v5+ioiJ+/etfExUVRW5uLjfffDOvvvoqfX19/OlPf+L8888f9fvTsuDKF3SQfRAY7IcoqWxk4/4mHb0UAE6nk+LiYv76178C7quHL3zhC4gIP/vZzygtLWXbtm289957bNu2bdTjbN68mdWrV1NeXs6aNWvYtGnT0HM33ngjmzZtYuvWrcyZM4fHH3+ciy++mOuuu46HHnqI8vJyZsw4MUCvu7ubW265heeee47t27cPnawHpaWlUVZWxu23337ak/JgWfBt27bxr//6r3zlK18BGCoLXl5ezvvvv09MTAx/+MMfuPLKKykvL2fr1q0sXLjwpLLgZWVlFBYW8sgjj9DY2MhLL73Ezp072bZtG/fcc885/fxVaNAriCBwXmYCCVEOfruhip5+F5fMmmDNS2N80venwWam5cuXs3r1ah5//HEA/vjHP7Jq1Sr6+/s5evQoFRUVzJ8/3+sx3n//fW644QZiY2MBuO66ExP/d+zYwT333ENzczPt7e0nNWd5s2fPHvLy8jjvPHf9rZtvvpnHHnuM7373u4A74QAUFBTw4osvjnksLQuufEGvIIKA3SYsykmhqr4Dh00ozptgCcIiy5cv56233qKsrIzOzk4KCgrYv38/Dz/8MG+99Rbbtm3jmmuuGbXM9+nccsst/OpXv2L79u3cd99953ycQYMlw8dTLlzLgquzoQkiSAw2My2alkx8lF7YBUJ8fDyXX345t95669Bqbq2trcTFxZGUlERtbe1QE9RoLrvsMl5++WW6urpoa2vj1VdfHXqura2NyZMn09fXN1SiGyAhIYG2trZTjjV79mwOHDgwVIr7f//3f/nkJz95Tt+blgVXvqBnoiAxmCC0/yGwVq5cyQ033MDq1asBWLBgAYsWLeL8889n6tSpQ00so8nPz+eLX/wiCxYsICMj46SS3Q888ACLFy8mPT2dxYsXDyWFL33pS3zta1/jl7/8Jc8///zQ/tHR0Tz55JN8/vOfH+qk/uY3v3lO35eWBVe+4Ldy31YItXLfw/X2u3h47R5uXZLHpKTwH8Gk5aDDm/5+Q8dY5b71CiJIRDps/MvV+g+llAoe2gehlFLKK00QyjLh1LypTtDfa/jQBKEsER0dTWNjo55MwowxhsbGRqKjw78fbSLQPghliezsbKqrqwnFNTzU2KKjo8nOzrY6DOUDmiCUJSIiIsjLy7M6DKXUGLSJSSmllFeaIJRSSnmlCUIppZRXYTWTWkTqgYNWxzFOaUCD1UEECf1ZnEx/HifTn8cJ4/lZ5Bhj0r09EVYJIhyISOlo094nGv1ZnEx/HifTn8cJ/vpZaBOTUkoprzRBKKWU8koTRPBZZXUAQUR/FifTn8fJ9Odxgl9+FtoHoZRSyiu9glBKKeWVJgillFJeaYIIAiIyVUTeEZEKEdkpIndaHVMwEBG7iGwRkdesjsVKIpIsIs+LyG4R2SUiF1kdk5VE5Hue/5MdIvKsiEyo0rEi8oSI1InIjmHbnCKyTkT2er6m+OK9NEEEh37gH40xc4FPAHeIyFyLYwoGdwK7rA4iCPwn8Lox5nxgARP4ZyIiWcB3gEJjzAWAHfiStVEF3FPAshHb7gbeMsbMAt7yPB43TRBBwBhz1BhT5rnfhvsEkGVtVNYSkWzgGuC3VsdiJRFJAi4DHgcwxvQaY5otDcp6DiBGRBxALHDE4ngCyhizHmgasXk58LTn/tPA9b54L00QQUZEcoFFwN8sDsVqjwI/AFwWx2G1PKAeeNLT3PZbEYmzOiirGGNqgIeBQ8BRoMUYs9baqIJCpjHmqOf+MSDTFwfVBBFERCQeeAH4rjGm1ep4rCIi1wJ1xpjNVscSBBxAPvBrY8wioAMfNR+EIk/b+nLciXMKECci/8faqIKLcc9d8Mn8BU0QQUJEInAnh2eMMS9aHY/FlgDXicgBYDXwaRH5vbUhWaYaqDbGDF5RPo87YUxUnwX2G2PqjTF9wIvAxRbHFAxqRWQygOdrnS8OqgkiCIiI4G5j3mWMecTqeKxmjPlnY0y2MSYXdwfk28aYCfkp0RhzDDgsIrM9mz4DVFgYktUOAZ8QkVjP/81nmMCd9sO8AtzsuX8z8GdfHFQTRHBYAvw97k/K5Z7b1VYHpYLGt4FnRGQbsBD4V2vDsY7nSup5oAzYjvscNqFKbojIs8CHwGwRqRaR24CfA1eIyF7cV1k/98l7aakNpZRS3ugVhFJKKa80QSillPJKE4RSSimvNEEopZTyShOEUkoprzRBKHUaIjIwbPhxuYj4bCaziOQOr8qpVDBxWB2AUiGgyxiz0OoglAo0vYJQ6hyJyAER+YWIbBeRjSIy07M9V0TeFpFtIvKWiEzzbM8UkZdEZKvnNlgiwi4iv/GscbBWRGI8+3/Hs0bINhFZbdG3qSYwTRBKnV7MiCamLw57rsUYcyHwK9wVaAH+P+BpY8x84Bngl57tvwTeM8YswF1Paadn+yzgMWPMPKAZuMmz/W5gkec43/TPt6bU6HQmtVKnISLtxph4L9sPAJ82xlR5ii0eM8akikgDMNkY0+fZftQYkyYi9UC2MaZn2DFygXWehV4QkR8CEcaYB0XkdaAdeBl42RjT7udvVamT6BWEUuNjRrl/NnqG3R/gRN/gNcBjuK82NnkWyFEqYDRBKDU+Xxz29UPP/Q84sQzml4H3PfffAm6HofW2k0Y7qIjYgKnGmHeAHwJJwClXMUr5k34iUer0YkSkfNjj140xg0NdUzxVVnuAlZ5t38a9Atw/4V4N7h882+8EVnmqbw7gThZH8c4O/N6TRAT4pS41qgJN+yCUOkeePohCY0yD1bEo5Q/axKSUUsorvYJQSinllV5BKKWU8koThFJKKa80QSillPJKE4RSSimvNEEopZTy6v8Hs1faC72FkpIAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Don't change these\n",
        "# plot training curves\n",
        "plt.figure()\n",
        "plt.plot(range(1, trainer.epochs + 1), trainer.train_losses, label='Training losses')\n",
        "plt.plot(range(1, trainer.epochs + 1), trainer.val_losses, label='Validation losses')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('NLL')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipdbmqaGSwRh"
      },
      "outputs": [],
      "source": [
        "# see generated output\n",
        "print (trainer.generated[-1]) # get last generated output"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
